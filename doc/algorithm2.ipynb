{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prejudice\n",
    "\n",
    "**Prejudice** means a statistical dependence between a sensitive variable,\n",
    "$S$, and the target variable, $Y$, or a non-sensitive variable, $X$.\n",
    "\n",
    "There are three types of prejudices:\n",
    "## Direct prejudice\n",
    "\n",
    "Direct prejudice is the use of a sensitive variable in a prediction model.\n",
    "\n",
    "To eliminate direct prejudice, we can remove the sensitive variable from the model.\n",
    "\n",
    "\n",
    "## Indirect prejudice\n",
    "\n",
    "Indirect prejudice is statistical dependence between a sensitive variable and a target variable.\n",
    "\n",
    "To remove this indirect prejudice, we must use a prediction model that satisfies the condition $Y \\perp\\!\\!\\!\\perp \\ S$.\n",
    "\n",
    "We can quantify the degree of indirect prejudice using the following equation where $PI$ refers to the (indirect) prejudice index and $\\cal{D}$ is the data set.\n",
    "\n",
    "$$\\text{PI} = \\sum_{(y, s) \\in \\cal{D}}  \\hat{\\text{Pr}}[y, s] \\ln \\frac{\\hat{\\text{Pr}}[y, s]}{\\hat{\\text{Pr}}[y]\\hat{\\text{Pr}}[s]}$$\n",
    "\n",
    "The application of the normalization technique for mutual information leads to a _normalized prejudice index_ (NPI)\n",
    "\n",
    "$$\\text{NPI} = \\frac{\\text{PI}}{\\sqrt{\\text{H}(Y)\\text{H}(S)}}$$\n",
    "\n",
    "where $\\text{H}(\\ \\cdot\\ )$ is the entropy function.\n",
    "\n",
    "## Latent prejudice\n",
    "Latent prejudice is a statistical dependence between a sensitive variable, $S$, and a non-sensitive variable, $X$.\n",
    "\n",
    "Removal of potential prejudice is achieved by making $X$ and $Y$ independent from $S$ simultaneously.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underestimation\n",
    "\n",
    "Underestimation is the state in which a learned model is not fully converged due to the finiteness of the size of a training data set.\n",
    "\n",
    "Despite that a prediction model without indirect prejudice can learn to make a fair determination, this is only the case if we have an \"infinitely large\" training data set. In general, training sets are finite and limited to small quantities of data, hence the model could output even more unfair determinations than that observed in the training sample distribution.\n",
    "\n",
    "To quantify the degree of underestimation, we assess the resultant difference between the training sample distribution over $\\cal{D}$, $\\tilde{\\text{Pr}}$ using the underestimation index (UEI) which is calculated using the Hellinger distance:\n",
    "\n",
    "$$\\text{UEI} = \\sqrt{\\frac{1}{2}\\sum_{(y, s) \\in \\cal{D}} \\left(\\sqrt{\\tilde{\\text{Pr}}[y, s]} - \\sqrt{\\hat{\\text{Pr}}[y, s]}\\right)^2} = \\sqrt{1 - \\sum_{(y, s) \\in \\cal{D}} \\sqrt{\\hat{\\text{Pr}}[Y, S]\\tilde{\\text{Pr}}[Y, S]}}$$\n",
    "\n",
    "where $\\hat{\\text{Pr}}$ is the distribution of the learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Legacy\n",
    "\n",
    "Negative legacy is unfair sampling or labeling in the training data. \n",
    "\n",
    "For example, if a bank has been refusing credit to minority people without\n",
    "assessing them, the records of minority people are less sampled in a training data\n",
    "set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Framework\n",
    "\n",
    "Given a training data set $\\cal{D} = $ $\\{(y, \\textbf{x}, s)\\}$, we can define the following terms:\n",
    "\n",
    "- $\\cal{M}$ $[ Y |X, S; \\mathbb{\\Theta}]$ conditional probability of a class given non-sensitive and sensitive features model.\n",
    "- $\\mathbb{\\Theta}$ set of model parameters. These parameters are estimates based on the maximum likelihood principle:\n",
    "$$\\cal{L}(\\cal{D}, \\mathbb{\\Theta}) = \\sum_{(y_i, \\textbf{x}_i, s_i) \\in \\cal{D}} \\ln \\cal{M} \\ [y_i|\\textbf{x}_i, s_i;\\mathbb{\\Theta}].$$\n",
    "\n",
    "For the optimization process, we use two types of regularizers, the $L_2$ regularizer $||\\mathbb{\\Theta}||_2^2$ and a second regularizer $R(\\cal{D}, \\mathbb{\\Theta})$, introduced to enforce fair classification. After applying both regularizing techniques, are objective function becomes:\n",
    "$$-\\cal{L}(\\cal{D}, \\mathbb{\\Theta}) + \\eta{} \\text{R}(\\cal{D}, \\mathbb{\\Theta}) + \\frac{\\lambda}{2} ||\\mathbb{\\Theta}||_2^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prejudice Remover\n",
    "\n",
    "A _prejudice remover_ regularizer directly tries to reduce the prejudice index and is denoted by $\\text{R}_{\\text{PR}}$. Recall that the prejudice index is defined as\n",
    "\n",
    "$$\\text{PI} = \\sum_{Y, S}  \\hat{\\text{Pr}}[Y, S] \\ln \\frac{\\hat{\\text{Pr}}[Y, S]}{\\hat{\\text{Pr}}[Y]\\hat{\\text{Pr}}[S]}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\hat{\\text{Pr}}[y|s_i] \\approx \\frac{\\sum_{(\\textbf{x}_i, s_i) \\in {\\cal{D}} \\text{ s.t. } s_i = s}{\\cal{M}}[y|\\textbf{x}_i, s; \\mathbb{\\Theta}]}{|\\left\\{(\\textbf{x}_i, s_i) \\in {\\cal{D}} \\text{ s.t. } s_i = s \\right\\}|}.$$\n",
    "\n",
    "$$\\hat{\\text{Pr}}[y] \\approx \\frac{\\sum_{(\\textbf{x}_i, s_i) \\in {\\cal{D}}}{\\cal{M}}[y|\\textbf{x}_i, s_i; \\mathbb{\\Theta}]}{|{\\cal{D}}|}.$$\n",
    "\n",
    "And the prejudice remover regularizer $\\text{R}_{\\text{PR}}({\\cal{D}}, \\mathbb{\\Theta})$ is defined as\n",
    "\n",
    "$$\\sum_{(\\textbf{x}_i, s_i) \\in {\\cal{D}}}\\sum_{y\\in\\{0, 1\\}}{\\cal{M}}[y|\\textbf{x}_i, s_i;\\mathbb{\\Theta}]\\ln\\frac{\\hat{\\text{Pr}}[y|s_i]}{\\hat{\\text{Pr}}[y]}$$\n",
    "\n",
    "This regularizer becomes increasingly large as a class $y$ becomes more likely to be predicted for a sensitive group $s$ than for the entire population, thus making the overall model is influenced less by the sensitive variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset\n",
    "\n",
    "For the analysis of the algorithm, we will be using the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) dataset over a period of two years. This dataset contains information about criminal defendants and their recidivism status. The complete dataset contains 52,000 records containing and 52 features. The dataset is available on the [ProPublica GitHub](https://github.com/propublica/compas-analysis) repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This URL corresponds to the ProPublica Compas Analysis dataset \n",
    "URL = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name   first         last compas_screening_date   sex  \\\n",
       "id                                                                        \n",
       "1     miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "3          kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "4             ed philo      ed        philo            2013-04-14  Male   \n",
       "5          marcu brown   marcu        brown            2013-01-13  Male   \n",
       "6   bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "           dob  age          age_cat              race  juv_fel_count  ...  \\\n",
       "id                                                                     ...   \n",
       "1   1947-04-18   69  Greater than 45             Other              0  ...   \n",
       "3   1982-01-22   34          25 - 45  African-American              0  ...   \n",
       "4   1991-05-14   24     Less than 25  African-American              0  ...   \n",
       "5   1993-01-21   23     Less than 25  African-American              0  ...   \n",
       "6   1973-01-22   43          25 - 45             Other              0  ...   \n",
       "\n",
       "    v_decile_score  v_score_text  v_screening_date  in_custody  out_custody  \\\n",
       "id                                                                            \n",
       "1                1           Low        2013-08-14  2014-07-07   2014-07-14   \n",
       "3                1           Low        2013-01-27  2013-01-26   2013-02-05   \n",
       "4                3           Low        2013-04-14  2013-06-16   2013-06-16   \n",
       "5                6        Medium        2013-01-13         NaN          NaN   \n",
       "6                1           Low        2013-03-26         NaN          NaN   \n",
       "\n",
       "   priors_count.1 start   end event two_year_recid  \n",
       "id                                                  \n",
       "1               0     0   327     0              0  \n",
       "3               0     9   159     1              1  \n",
       "4               4     0    63     0              1  \n",
       "5               1     0  1174     0              0  \n",
       "6               2     0  1102     0              0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(URL, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary ETA and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  (7214, 52)\n",
      "name                          0\n",
      "first                         0\n",
      "last                          0\n",
      "compas_screening_date         0\n",
      "sex                           0\n",
      "dob                           0\n",
      "age                           0\n",
      "age_cat                       0\n",
      "race                          0\n",
      "juv_fel_count                 0\n",
      "decile_score                  0\n",
      "juv_misd_count                0\n",
      "juv_other_count               0\n",
      "priors_count                  0\n",
      "days_b_screening_arrest     307\n",
      "c_jail_in                   307\n",
      "c_jail_out                  307\n",
      "c_case_number                22\n",
      "c_offense_date             1159\n",
      "c_arrest_date              6077\n",
      "c_days_from_compas           22\n",
      "c_charge_degree               0\n",
      "c_charge_desc                29\n",
      "is_recid                      0\n",
      "r_case_number              3743\n",
      "r_charge_degree            3743\n",
      "r_days_from_arrest         4898\n",
      "r_offense_date             3743\n",
      "r_charge_desc              3801\n",
      "r_jail_in                  4898\n",
      "r_jail_out                 4898\n",
      "violent_recid              7214\n",
      "is_violent_recid              0\n",
      "vr_case_number             6395\n",
      "vr_charge_degree           6395\n",
      "vr_offense_date            6395\n",
      "vr_charge_desc             6395\n",
      "type_of_assessment            0\n",
      "decile_score.1                0\n",
      "score_text                    0\n",
      "screening_date                0\n",
      "v_type_of_assessment          0\n",
      "v_decile_score                0\n",
      "v_score_text                  0\n",
      "v_screening_date              0\n",
      "in_custody                  236\n",
      "out_custody                 236\n",
      "priors_count.1                0\n",
      "start                         0\n",
      "end                           0\n",
      "event                         0\n",
      "two_year_recid                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size: \", df.shape)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_records(df: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:\n",
    "    \"\"\"Remove records with missing values above a threshold.\"\"\"\n",
    "    # Get the number of missing values per column\n",
    "    missing = df.isna().sum()\n",
    "    # Get the columns with missing values above the threshold\n",
    "    cols = missing[missing > threshold * df.shape[0]].index\n",
    "    # Remove the columns\n",
    "    df = df.drop(cols, axis=1)\n",
    "    # Remove the rows with missing values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def inpute_missing_data(df):\n",
    "    \"\"\"Inpute missing data with the mean.\"\"\"\n",
    "    # Get the number of missing values per column\n",
    "    missing = df.isna().sum()\n",
    "    # Get the columns with missing values\n",
    "    cols = missing[missing > 0].index\n",
    "    # Inpute the missing values with the mean\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    return df\n",
    "\n",
    "def encode_categorical_features(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"Encode categorical features.\"\"\"\n",
    "    # Get the categorical features\n",
    "    categorical = df.loc[:, columns].select_dtypes(include=\"object\").columns\n",
    "    # Encode the categorical features\n",
    "    for col in categorical:\n",
    "        df[col] = pd.factorize(df[col])[0]\n",
    "    return df\n",
    "\n",
    "def parse_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse the dates.\"\"\"\n",
    "    # Convert the dates to datetime objects\n",
    "    date_columns = df.columns.str.endswith(\"_date\")\n",
    "    for col in df.loc[:, date_columns].columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess the data.\"\"\"\n",
    "    # Remove the records with missing values\n",
    "    df = remove_missing_records(df)\n",
    "    # Inpute the missing values\n",
    "    df = inpute_missing_data(df)\n",
    "    # Encode the categorical features\n",
    "    df = encode_categorical_features(df, columns)\n",
    "    # Parse the dates\n",
    "    df = parse_dates(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>0</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>0</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>marsha miles</td>\n",
       "      <td>marsha</td>\n",
       "      <td>miles</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1971-08-22</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edward riddle</td>\n",
       "      <td>edward</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1974-07-23</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   first       last compas_screening_date  sex  \\\n",
       "id                                                                   \n",
       "1   miguel hernandez  miguel  hernandez            2013-08-14    0   \n",
       "3        kevon dixon   kevon      dixon            2013-01-27    0   \n",
       "4           ed philo      ed      philo            2013-04-14    0   \n",
       "7       marsha miles  marsha      miles            2013-11-30    0   \n",
       "8      edward riddle  edward     riddle            2014-02-19    0   \n",
       "\n",
       "           dob  age  age_cat  race  juv_fel_count  ...  v_decile_score  \\\n",
       "id                                                 ...                   \n",
       "1   1947-04-18   69        0     0              0  ...               1   \n",
       "3   1982-01-22   34        1     1              0  ...               1   \n",
       "4   1991-05-14   24        2     1              0  ...               3   \n",
       "7   1971-08-22   44        1     0              0  ...               1   \n",
       "8   1974-07-23   41        1     2              0  ...               2   \n",
       "\n",
       "    v_score_text  v_screening_date  in_custody  out_custody priors_count.1  \\\n",
       "id                                                                           \n",
       "1            Low        2013-08-14  2014-07-07   2014-07-14              0   \n",
       "3            Low        2013-01-27  2013-01-26   2013-02-05              0   \n",
       "4            Low        2013-04-14  2013-06-16   2013-06-16              4   \n",
       "7            Low        2013-11-30  2013-11-30   2013-12-01              0   \n",
       "8            Low        2014-02-19  2014-03-31   2014-04-18             14   \n",
       "\n",
       "   start  end event  two_year_recid  \n",
       "id                                   \n",
       "1      0  327     0               0  \n",
       "3      9  159     1               1  \n",
       "4      0   63     0               1  \n",
       "7      1  853     0               0  \n",
       "8      5   40     1               1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"sex\", \"race\", \"age_cat\"]\n",
    "df = preprocess_data(df, columns)\n",
    "print(\"Missing values: \", df.isna().values.sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_density(model, y, s, features):\n",
    "    \"\"\"Probability of label given sensitive variable.\"\"\"\n",
    "    obs = 0\n",
    "    n = 0\n",
    "    for xi, si in features:\n",
    "        if si == s:\n",
    "            obs += model(y, xi, s)\n",
    "            n += 1\n",
    "    if n == 0:\n",
    "        return 0\n",
    "\n",
    "    return obs / n\n",
    "\n",
    "def density(model, y, features):\n",
    "    \"\"\"Probability of label.\"\"\"\n",
    "    obs = 0\n",
    "    n = len(features)\n",
    "\n",
    "    for xi, si in features:\n",
    "        obs += model(y, xi, si)\n",
    "\n",
    "    return obs / n\n",
    "\n",
    "\n",
    "def prejudice_remover_regularizer(model, features, labels):\n",
    "    \"\"\"Prejudice remover regularizer.\"\"\"\n",
    "    result = 0\n",
    "    for xi, si in features:\n",
    "        for y in labels:\n",
    "            p1 = conditional_density(model, y, si, features)\n",
    "            p2 = density(model, y, features)\n",
    "            q = p1/ p2\n",
    "            log_odds = np.log(q) \n",
    "            result += log_odds * model(y, xi, si)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.w = tf.Variable(tf.random.normal(shape=(num_features, 1)), name=\"w\")\n",
    "        self.b = tf.Variable(tf.zeros(shape=(1,)), name=\"b\")\n",
    "    \n",
    "    def call(self, y, x, s, training=None):\n",
    "\n",
    "        # Logistic model\n",
    "        matmul = tf.matmul(x, self.w)\n",
    "        sigmoid = tf.nn.sigmoid(matmul + self.b)\n",
    "        model_output = y * sigmoid + (1 - y) * (1 - sigmoid)\n",
    "\n",
    "        return model_output\n",
    "\n",
    "class FairnessModel(tf.keras.Model):\n",
    "    \"\"\"Fairness model.\"\"\"\n",
    "    def __init__(self, model, features, labels):\n",
    "        super(FairnessModel, self).__init__()\n",
    "        \n",
    "        self.eta = tf.Variable(0.01)\n",
    "        self.lam = tf.Variable(0.01)\n",
    "\n",
    "        self.model = LogisticRegression(len(features), 2)\n",
    "        self.features = features\n",
    "        self.labels = labels      \n",
    "        self.R_pr = prejudice_remover_regularizer\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, D):\n",
    "        \"\"\"Call the model.\"\"\"\n",
    "        y, x, s = D\n",
    "\n",
    "        # Compute the model output\n",
    "        model_output = self.model(y, x, s)\n",
    "\n",
    "        # Prejudice remover regularizer\n",
    "        R_pr = self.R_pr(model_output)\n",
    "        regularizer = self.eta * self.R_pr\n",
    "\n",
    "        # l2 regularization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"Objective function.\"\"\"\n",
    "    eta = \n",
    "    R_pr = prejudice_remover_regularizer(model, features, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, test_labels, test_imgs):\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    for image in test_imgs:\n",
    "        y_pred.append(model(image))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b68576675d14688f13df6495c027427b1fa86cc0b514974591414d368704a84c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
